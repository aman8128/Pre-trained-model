def convert_image_to_svg(image_path, output_path, n_colors=18, min_area=3):
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    h, w, _ = img_np.shape

    # âœ¨ Gaussian blur before clustering
    blurred = cv2.GaussianBlur(img_np, (5, 5), 0)

    reshaped = blurred.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=42).fit(reshaped)
    labels = kmeans.labels_.reshape((h, w))
    cluster_centers = np.uint8(kmeans.cluster_centers_)

    dwg = svgwrite.Drawing(output_path, profile='full', size=(f"{w}px", f"{h}px"))
    dwg.viewbox(0, 0, w, h)

    for idx in range(n_colors):
        mask = np.uint8((labels == idx) * 255)

        # âœ¨ Feathering with blur + threshold for soft mask
        mask = cv2.GaussianBlur(mask, (5, 5), 0)
        _, mask = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)

        # âœ¨ Morphological smoothing
        kernel = np.ones((3, 3), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.dilate(mask, kernel, iterations=1)

        # ðŸ§  Find all contours
        contours, _ = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)

        color = cluster_centers[idx]
        fill = f"rgb({int(color[0])},{int(color[1])},{int(color[2])})"

        for contour in contours:
            if len(contour) < 3 or cv2.contourArea(contour) < min_area:
                continue

            # âœ¨ More adaptive smoothing
            epsilon = 0.001 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            points = [f"{pt[0][0]},{pt[0][1]}" for pt in approx]
            d = f"M {' L '.join(points)} Z"

            dwg.add(dwg.path(
                d=d,
                fill=fill,
                stroke="none",  # or stroke="black" for debugging
                stroke_width=0.3,
                id=f"path_{uuid.uuid4().hex[:6]}"
            ))

    dwg.save()
    print(f"âœ… Saved Enhanced SVG: {output_path}")


    
# def convert_image_to_svg(image_path, output_path, n_colors=12, min_area=40):
#     # Load and preprocess image
#     img = Image.open(image_path).convert("RGB")
#     img_np = np.array(img)
#     h, w, _ = img_np.shape

#     print(f"ðŸ”¹ Image size: {w}x{h} | Extracting {n_colors} colors...")

#     # Step 1: KMeans color quantization with fine-tuned clustering
#     reshaped = img_np.reshape((-1, 3))
#     kmeans = KMeans(n_clusters=n_colors, random_state=0, n_init=10).fit(reshaped)  # Improved clustering
#     labels = kmeans.labels_.reshape((h, w))
#     cluster_centers = np.uint8(kmeans.cluster_centers_)

#     # Step 2: Start drawing SVG
#     dwg = svgwrite.Drawing(output_path, profile='full', size=(f"{w}px", f"{h}px"))
#     dwg.viewbox(0, 0, w, h)

#     # Step 3: For each color, extract contours
#     for idx in range(n_colors):
#         print(f"ðŸ”¸ Processing color {idx+1}/{n_colors}")
#         mask = np.uint8((labels == idx) * 255)

#         # Refined mask processing: Use more dilation and erosion to capture accurate edges
#         kernel = np.ones((3, 3), np.uint8)
#         mask = cv2.dilate(mask, kernel, iterations=2)  # Fine-tuned dilation
#         mask = cv2.erode(mask, kernel, iterations=1)  # Erosion to clean unnecessary small areas

#         # Find contours
#         contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

#         rgb = cluster_centers[idx]
#         fill = f"rgb({rgb[0]},{rgb[1]},{rgb[2]})"

#         # Adding contours to SVG
#         for contour in contours:
#             if len(contour) < 5 or cv2.contourArea(contour) < min_area:
#                 continue

#             points = [f"{pt[0][0]},{pt[0][1]}" for pt in contour]
#             path_data = f"M {' L '.join(points)} Z"
#             dwg.add(dwg.path(d=path_data, fill=fill, stroke="none", id=f"path_{uuid.uuid4().hex[:6]}"))

#     dwg.save()
#     print(f"âœ… Layered SVG saved: {output_path}")

def convert_image_to_svg(image_path, output_path, min_area=5, quality='auto'):
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    h, w, _ = img_np.shape

    # ðŸ” Adjust number of colors based on image size/quality
    if quality == 'auto':
        base = (h * w) / (300 * 300)
        n_colors = int(np.clip(base * 10, 6, 30))  # 6â€“30 range
    else:
        n_colors = quality  # allow manual override

    # âœ¨ Slight blur to improve color separation
    blurred = cv2.GaussianBlur(img_np, (3, 3), 0)
    reshaped = blurred.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=42).fit(reshaped)
    labels = kmeans.labels_.reshape((h, w))
    cluster_centers = np.uint8(kmeans.cluster_centers_)

    dwg = svgwrite.Drawing(output_path, profile='full', size=(f"{w}px", f"{h}px"))
    dwg.viewbox(0, 0, w, h)

    for idx in range(n_colors):
        mask = np.uint8((labels == idx) * 255)

        # Adaptive mask cleaning
        mask = cv2.GaussianBlur(mask, (3, 3), 0)
        _, mask = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)
        kernel = np.ones((2, 2), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.dilate(mask, kernel, iterations=1)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        color = cluster_centers[idx]
        fill = f"rgb({color[0]},{color[1]},{color[2]})"

        for contour in contours:
            if cv2.contourArea(contour) < min_area:
                continue

            epsilon = 0.001 * cv2.arcLength(contour, True)
            approx = cv2.approxPolyDP(contour, epsilon, True)
            points = [f"{pt[0][0]},{pt[0][1]}" for pt in approx]
            d = f"M {' L '.join(points)} Z"

            dwg.add(dwg.path(d=d, fill=fill, stroke="none", id=f"path_{uuid.uuid4().hex[:6]}"))

    dwg.save()
    print(f"âœ… Final SVG saved to: {output_path}")


def convert_image_to_svg(image_path, output_path, min_area_ratio=0.00002, quality='auto'):
    img = Image.open(image_path).convert("RGB")
    img_np = np.array(img)
    h, w, _ = img_np.shape
    total_pixels = h * w

    # Adaptive number of colors
    if quality == 'auto':
        n_colors = int(np.clip(total_pixels / 4000, 8, 30))  # Dynamic color range
    else:
        n_colors = quality

    blurred = cv2.GaussianBlur(img_np, (3, 3), 0)
    reshaped = blurred.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors, n_init=10, random_state=42).fit(reshaped)
    labels = kmeans.labels_.reshape((h, w))
    cluster_centers = np.uint8(kmeans.cluster_centers_)

    dwg = svgwrite.Drawing(output_path, profile='full', size=(f"{w}px", f"{h}px"))
    dwg.viewbox(0, 0, w, h)

    min_area = min_area_ratio * total_pixels  # âœ¨ Adaptive area based on image size

    for idx in range(n_colors):
        mask = np.uint8((labels == idx) * 255)
        mask = cv2.GaussianBlur(mask, (3, 3), 0)
        _, mask = cv2.threshold(mask, 40, 255, cv2.THRESH_BINARY)
        kernel = np.ones((2, 2), np.uint8)
        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)
        mask = cv2.dilate(mask, kernel, iterations=1)

        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        color = cluster_centers[idx]
        fill = f"rgb({color[0]},{color[1]},{color[2]})"

        for contour in contours:
            area = cv2.contourArea(contour)
            if area < min_area:
                continue

            epsilon = 0.0008 * cv2.arcLength(contour, True)  # smoother curves
            approx = cv2.approxPolyDP(contour, epsilon, True)
            points = [f"{pt[0][0]},{pt[0][1]}" for pt in approx]
            d = f"M {' L '.join(points)} Z"

            dwg.add(dwg.path(d=d, fill=fill, stroke="none", id=f"path_{uuid.uuid4().hex[:6]}"))

    dwg.save()
    print(f"âœ… Final improved SVG saved: {output_path}")

def convert_image_to_svg(image_path, output_path, n_colors=12, min_area=40):
    # Step 1: Read image using OpenCV and convert it to RGB
    img = cv2.imread(image_path)
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Step 2: KMeans for color quantization (to reduce colors in the image)
    img_flattened = img_rgb.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(img_flattened)
    labels = kmeans.labels_.reshape(img_rgb.shape[:2])

    # Step 3: Segmentation of image using scikit-image regionprops
    segmented_image = np.zeros_like(img_rgb)

    for i in range(n_colors):
        mask = (labels == i).astype(np.uint8) * 255
        contours = measure.find_contours(mask, level=0.5)

        for contour in contours:
            if len(contour) < min_area:
                continue

            # Create paths for SVG
            path_data = "M " + " L ".join([f"{point[1]},{point[0]}" for point in contour]) + " Z"
            dwg.add(dwg.path(d=path_data, fill=f"rgb({int(kmeans.cluster_centers_[i][0])},{int(kmeans.cluster_centers_[i][1])},{int(kmeans.cluster_centers_[i][2])})", stroke="none"))

    # Step 4: Save the SVG output
    dwg.save()
    print(f"SVG saved at: {output_path}")

def convert_image_to_svg(image_path, output_path, n_colors=12, min_area=40):
    # Step 1: Read image using OpenCV and convert it to RGB
    img = cv2.imread(image_path)
    if img is None:
        print(f"âŒ Error: Image not found at {image_path}")
        return
    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

    # Step 2: KMeans for color quantization (to reduce colors in the image)
    img_flattened = img_rgb.reshape((-1, 3))
    kmeans = KMeans(n_clusters=n_colors, random_state=0).fit(img_flattened)
    labels = kmeans.labels_.reshape(img_rgb.shape[:2])

    # Step 3: Initialize SVG file
    try:
        dwg = svgwrite.Drawing(output_path, profile='full', size=(f"{img_rgb.shape[1]}px", f"{img_rgb.shape[0]}px"))
        print(f"ðŸ”¹ SVG file initialized at {output_path}")
    except Exception as e:
        print(f"âŒ Error initializing SVG file: {e}")
        return

    # Step 4: Segmentation of image using scikit-image regionprops
    for i in range(n_colors):
        mask = (labels == i).astype(np.uint8) * 255
        contours = measure.find_contours(mask, level=0.5)

        for contour in contours:
            if len(contour) < min_area:
                continue

            # Create paths for SVG
            path_data = "M " + " L ".join([f"{point[1]},{point[0]}" for point in contour]) + " Z"
            try:
                dwg.add(dwg.path(d=path_data, fill=f"rgb({int(kmeans.cluster_centers_[i][0])},{int(kmeans.cluster_centers_[i][1])},{int(kmeans.cluster_centers_[i][2])})", stroke="none"))
            except Exception as e:
                print(f"âŒ Error adding path to SVG: {e}")

    # Step 5: Save the SVG output
    try:
        dwg.save()
        print(f"âœ… SVG saved at: {output_path}")
    except Exception as e:
        print(f"âŒ Error saving SVG file: {e}")
        return


def convert_image_to_svg(image_path: str, svg_path: str):
    # Open the image
    img = Image.open(image_path)
    img = img.convert("L")  # Convert to grayscale

    # Create SVG drawing
    dwg = svgwrite.Drawing(svg_path, profile='tiny', size=(img.width, img.height))

    # Iterate through each pixel in the image and create corresponding SVG shapes
    for y in range(img.height):
        for x in range(img.width):
            pixel_value = img.getpixel((x, y))

            # If the pixel is not white (threshold for black and white images)
            if pixel_value < 200:  # You can adjust this threshold
                # Draw a small rectangle for each black pixel
                dwg.add(dwg.rect(insert=(x, y), size=(1, 1), fill='black'))

    # Save the SVG
    dwg.save()
    print(f"Image successfully converted to SVG and saved at: {svg_path}")

from scour.scour import scourString, parse_args

def convert_image_to_svg(input_path, output_path):
    # Ensure the output directory exists
    output_directory = os.path.dirname(output_path)
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    # Step 1: Convert the image to SVG
    vtracer.convert_image_to_svg_py(input_path, output_path)

    # Step 2: Optimize the generated SVG to enhance quality
    with open(output_path, 'r', encoding='utf-8') as svg_file:
        svg_content = svg_file.read()

    # Prepare scour options
    options = parse_args([])  # Default options
    options.remove_metadata = True
    options.remove_descriptive_elements = True
    options.shorten_ids = True
    options.strip_comments = True
    options.enable_viewboxing = True
    options.keep_editor_data = False

    # Optimize the SVG (only one return value now!)
    optimized_svg = scourString(svg_content, options)

    # Save the optimized SVG
    with open(output_path, 'w', encoding='utf-8') as optimized_svg_file:
        optimized_svg_file.write(optimized_svg)


right code for image_converter.py :

from fastapi import APIRouter, UploadFile, File, Form
from fastapi.responses import JSONResponse
import os
import shutil
from services.convert_image import convert_image

router = APIRouter()

@router.post("/convert-image/")
async def convert_image_route(
    input_file: UploadFile = File(...),
    output_format: str = Form(...),
    output_filename: str = Form(default="converted_output")
):
    try:
        input_ext = input_file.filename.split(".")[-1].lower()
        temp_input_path = f"temp_input.{input_ext}"
        temp_output_path = f"{output_filename}.{output_format.lower()}"

        with open(temp_input_path, "wb") as buffer:
            shutil.copyfileobj(input_file.file, buffer)

        print(f"ðŸ”¹ Saved temp input file: {temp_input_path}")
        print(f"ðŸ”¹ Target output path: {temp_output_path}")

        convert_image(temp_input_path, temp_output_path)

        if not os.path.exists(temp_output_path):
            print("âŒ Output file was not created!")
            return JSONResponse(content={"error": "Conversion failed or file not found"}, status_code=500)

        return JSONResponse(content={"message": "File converted successfully"}, status_code=200)

    except Exception as e:
        print("âŒ Exception:", str(e))
        return JSONResponse(content={"error": str(e)}, status_code=500)

    finally:
        if os.path.exists(temp_input_path):
            os.remove(temp_input_path)



from fastapi import APIRouter, UploadFile, File, Form
from fastapi.responses import JSONResponse
import os
import shutil
from services.convert_image import convert_image

router = APIRouter()

@router.post("/convert-image/")
async def convert_image_route(
    input_file: UploadFile = File(...),
    output_format: str = Form(...),
    output_filename: str = Form(default="converted_output")
):
    try:
        temp_input_path = None
        # Validate output format
        valid_formats = ['svg', 'png', 'jpg', 'jpeg']  # Add more formats as needed
        if output_format.lower() not in valid_formats:
            return JSONResponse(content={"error": "Invalid output format. Supported formats: " + ", ".join(valid_formats)}, status_code=400)

        input_ext = input_file.filename.split(".")[-1].lower()
        temp_input_path = f"temp_input.{input_ext}"

        temp_output_path = os.path.join(f"{output_filename}.{output_format.lower()}")

        # Save the uploaded file to a temporary path
        with open(temp_input_path, "wb") as buffer:
            shutil.copyfileobj(input_file.file, buffer)

        print(f"ðŸ”¹ Saved temp input file: {temp_input_path}")
        print(f"ðŸ”¹ Target output path: {temp_output_path}")

        # Call the conversion function
        convert_image(temp_input_path, temp_output_path)

        # Check if the output file was created
        if not os.path.exists(temp_output_path):
            print("Output file was not created!")
            return JSONResponse(content={"error": "Conversion failed or file not found"}, status_code=500)

        # Return a success message with the output file name
        return JSONResponse(content={"message": "File converted successfully", "output_file": temp_output_path}, status_code=200)

    except Exception as e:
        print("Exception:", str(e))
        return JSONResponse(content={"error": str(e)}, status_code=500)

    finally:
        # Clean up the temporary input file
        if os.path.exists(temp_input_path):
            os.remove(temp_input_path)


chat service.py :

import torch, re, os, pickle, time
from transformers import AutoTokenizer, AutoModelForCausalLM

# ðŸ§  Ultra Fast Rule-Based Mode
ultra_fast_mode = True

# Device setup
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using device: {device}")

# Model Load
model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
tokenizer = AutoTokenizer.from_pretrained(model_name)
tokenizer.pad_token = tokenizer.eos_token
model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto")

# File paths
HISTORY_FILE = "chat_history.pkl"
MEMORY_FILE = "bot_memory.pkl"

# Load/save utilities
def load_pickle(file_path, default):
    if os.path.exists(file_path):
        with open(file_path, "rb") as f:
            return pickle.load(f)
    return default

def save_pickle(file_path, data):
    with open(file_path, "wb") as f:
        pickle.dump(data, f)

# Load memory and chat
chat_history = load_pickle(HISTORY_FILE, [])
bot_memory = load_pickle(MEMORY_FILE, {
    "name": "Cvu-ai",
    "user_name": ""
})

# Ultra fast rule-based replies
def fast_reply(prompt):
    small_talk = {
        "hi": "Hey there! How can I help you today?",
        "hii": "Hii! How are you?",
        "hey": "Hey! How can I assist you?",
        "hello": "Hello! How can I help you?",
        "how are you": "I'm doing great thanks! How about you?",
        "how are you doing": "I'm doing great thanks! How about you?",
        "what's your name": f"My name is {bot_memory['name']}.",
        "who made you": "I was built by my creator using TinyLlama model!",
        "thank you": "You're most welcome!",
    }
    prompt_clean = prompt.lower().strip("?!. ")
    return small_talk.get(prompt_clean, None)

# Build full prompt with history
def build_prompt(prompt):
    memory_context = f"You are a helpful assistant named {bot_memory['name']}. Respond quickly and briefly.\n"
    memory_context += "Use past chat history for better replies. Be friendly, concise, and smart.\n\n"

    history = ""
    for exchange in chat_history[-4:]:
        history += f"User: {exchange['user']}\nAI: {exchange['ai']}\n"

    return memory_context + history + f"User: {prompt}\nAI:"

# Clean model output (remove extra junk)
def clean_generated_text(raw_output, final_prompt):
    text = raw_output[len(final_prompt):]  # Remove the prompt part
    text = text.strip()

    # Split by known patterns if extra stuff
    text = text.split("User:")[0]
    text = text.split("user:")[0]
    text = text.split("AI:")[0]

    # Clean unwanted leftovers
    text = text.strip("\n ").replace("\n", " ").strip()

    return text

# Generate AI reply
def generate_reply(prompt):
    global chat_history, bot_memory

    print(f"\nðŸ§  USER: {prompt}")

    # Save user name if mentioned
    if "my name is" in prompt.lower():
        match = re.search(r"my name is\s+([A-Za-z0-9_-]+)", prompt, re.IGNORECASE)
        if match:
            bot_memory["user_name"] = match.group(1)
            save_pickle(MEMORY_FILE, bot_memory)
            ai_reply = f"Nice to meet you, {bot_memory['user_name']}!"
            _save_chat(prompt, ai_reply)
            print("ðŸ¤– AI:", ai_reply)
            return ai_reply

    # Save bot name if mentioned
    if "your name is" in prompt.lower():
        match = re.search(r"your name is\s+([A-Za-z0-9_-]+)", prompt, re.IGNORECASE)
        if match:
            bot_memory["name"] = match.group(1)
            save_pickle(MEMORY_FILE, bot_memory)
            ai_reply = f"Alright! You can call me {bot_memory['name']}."
            _save_chat(prompt, ai_reply)
            print("ðŸ¤– AI:", ai_reply)
            return ai_reply

    # Ultra fast small-talk
    if ultra_fast_mode:
        fast = fast_reply(prompt)
        if fast:
            _save_chat(prompt, fast)
            print("âš¡ FAST REPLY:", fast)
            return fast

    # Full model generation
    final_prompt = build_prompt(prompt)
    inputs = tokenizer(final_prompt, return_tensors="pt", truncation=True, max_length=512).to(device)

    start = time.time()
    model.eval()
    with torch.no_grad():
        output = model.generate(
            **inputs,
            max_new_tokens=100,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id
        )
    end = time.time()

    raw_output = tokenizer.decode(output[0], skip_special_tokens=True)
    ai_reply = clean_generated_text(raw_output, final_prompt)

    _save_chat(prompt, ai_reply)

    print(f"ðŸ¤– AI (in {round(end-start,2)}s): {ai_reply}")
    return ai_reply

# Save conversation
def _save_chat(user, ai):
    chat_history.append({"user": user, "ai": ai})
    save_pickle(HISTORY_FILE, chat_history)

def convert_image_to_svg(input_path, output_path):
    output_directory = os.path.dirname(output_path)
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    original = Image.open(input_path).convert("RGBA")
    np_image = np.array(original)

    rgb = np_image[:, :, :3]
    alpha = np_image[:, :, 3]

    # ðŸ§  Apply edge-preserving smooth sharpening
    edge_preserved = cv2.edgePreservingFilter(rgb, flags=1, sigma_s=50, sigma_r=0.2)
    blurred = cv2.GaussianBlur(edge_preserved, (0, 0), sigmaX=1.0, sigmaY=1.0)
    sharpened = cv2.addWeighted(edge_preserved, 1.5, blurred, -0.5, 0)

    final = np.dstack([sharpened, alpha])

    enhanced_image_path = "enhanced_temp_image.png"
    Image.fromarray(final).save(enhanced_image_path)

    vtracer.convert_image_to_svg_py(
        enhanced_image_path,
        output_path,
        mode="spline",
        filter_speckle=5,
    )

    print(f"âœ… Final polished SVG saved at: {output_path}")


convert_image.py :

def convert_image_to_svg(input_path, output_path):
    output_directory = os.path.dirname(output_path)
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    # Load image with alpha channel preservation
    original = Image.open(input_path).convert("RGBA")
    np_image = np.array(original)
    width, height = original.size

    rgb = np_image[:, :, :3]
    alpha = np_image[:, :, 3]

    # Step 1: Smart upscaling (only if image is small)
    if width < 1000 or height < 1000:
        upscale_factor = 2
        rgb_up = cv2.resize(rgb, 
                          (rgb.shape[1]*upscale_factor, rgb.shape[0]*upscale_factor),
                          interpolation=cv2.INTER_LANCZOS4)
        alpha_up = cv2.resize(alpha,
                            (alpha.shape[1]*upscale_factor, alpha.shape[0]*upscale_factor),
                            interpolation=cv2.INTER_LANCZOS4)
    else:
        rgb_up = rgb
        alpha_up = alpha

    # Step 2: Gentle edge-preserving filter
    edge_preserved = cv2.edgePreservingFilter(rgb_up, flags=1, sigma_s=30, sigma_r=0.15)

    # Step 3: Very subtle sharpening
    blurred = cv2.GaussianBlur(edge_preserved, (0, 0), 0.5)
    sharpened = cv2.addWeighted(edge_preserved, 1.05, blurred, -0.05, 0)

    # Step 4: Merge with alpha channel
    final = np.dstack([sharpened, alpha_up])

    # Save temporary image with maximum quality
    enhanced_image_path = "enhanced_temp_image.png"
    Image.fromarray(final).save(enhanced_image_path, quality=100, compress_level=1)

    # Step 5: Optimized SVG conversion
    vtracer.convert_image_to_svg_py(
        enhanced_image_path,
        output_path,
        mode="spline",  # Better for smooth edges
        filter_speckle=6,
        color_precision=8,
        layer_difference=12,
        corner_threshold=75,  # Higher for smoother curves
        length_threshold=4.0,
        max_iterations=10,
        path_precision=6,
    )

    # Clean up
    os.remove(enhanced_image_path)
    
    # Post-process SVG for better rendering
    optimize_svg(output_path)
    
    print(f"âœ… High-quality SVG saved at: {output_path}")

def optimize_svg(svg_path):
    """Optimize SVG file for better rendering"""
    with open(svg_path, 'r') as f:
        svg_content = f.read()
    
    # Remove unnecessary elements
    optimized = scourString(svg_content, {
        'enable_viewboxing': True,
        'strip_ids': True,
        'strip_comments': True,
        'strip_xml_prolog': False,
        'shorten_ids': False,
        'indent_type': 'none'
    })
    
    with open(svg_path, 'w') as f:
        f.write(optimized)

def convert_image_to_svg(input_path, output_path):
    output_directory = os.path.dirname(output_path)
    if not os.path.exists(output_directory):
        os.makedirs(output_directory)

    original = Image.open(input_path).convert("RGBA")
    np_image = np.array(original)

    rgb = np_image[:, :, :3]
    alpha = np_image[:, :, 3]

    # Step 1: Upscale
    rgb_up = cv2.resize(rgb, (rgb.shape[1]*2, rgb.shape[0]*2), interpolation=cv2.INTER_CUBIC)
    alpha_up = cv2.resize(alpha, (alpha.shape[1]*2, alpha.shape[0]*2), interpolation=cv2.INTER_CUBIC)

    # Step 2: Edge-preserving filter
    edge_preserved = cv2.edgePreservingFilter(rgb_up, flags=1, sigma_s=50, sigma_r=0.2)

    # Step 3: Subtle sharpening (Unsharp Mask style)
    gaussian = cv2.GaussianBlur(edge_preserved, (5, 5), 0)
    sharpened = cv2.addWeighted(edge_preserved, 1.2, gaussian, -0.2, 0)

    # Step 4: Merge alpha and save temp image
    final = np.dstack([sharpened, alpha_up])
    enhanced_image_path = "enhanced_temp_image.png"
    Image.fromarray(final).save(enhanced_image_path)

    # Step 5: Convert to SVG using vtracer
    vtracer.convert_image_to_svg_py(
        enhanced_image_path,
        output_path,
        mode="polygon",  # Try 'polygon' for sharper edges
        filter_speckle=5,
        color_precision=8,
    )

    os.remove(enhanced_image_path)
    print(f"âœ… Final polished SVG saved at: {output_path}")